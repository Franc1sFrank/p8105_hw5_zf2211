---
title: "p8105_hw5_zf2211"
author: "Francis"
date: "11/6/2018"
output: github_document
---
### Problem 1
```{r}
#load packages
library(tidyverse)
```

```{r}
# conbine all file names into one dataframe
file = as.data.frame(list.files(path = "./data")[1:20]) 
# rename column
colnames(file)[1] = 'path'
```

```{r}
# create a function to read data one by one 
read_files = function (path) {
  df = 
    read.csv(str_c("./data/", path)) %>% 
    janitor::clean_names() %>% 
    as.data.frame()
  df
}
```

```{r}
# save the results as new variables in the dataframe
data <- 
  map(file$path, read_files) %>% 
  bind_rows()
data <- 
bind_cols(file, data)
```

```{r}
## tidy dataset
# transform the dataframe in one colume
# clean variable names
data <-  
  data %>% 
  gather(key = week, value = value, week_1:week_8) %>% 
  separate(path, into = c("group", "appendix"), sep = "_") %>% 
  separate(appendix, into = c("ID", "remove_1"), sep = 2 ) %>% 
  separate(week, into = c("remove_2", "week"), sep = "_") %>% 
  select(-remove_1, -remove_2) %>% 
  mutate(group = as.factor(group)) %>% 
  arrange(group, ID, week)
```


```{r}
# spaghette plot showing observations on each subject over time
data %>% 
  group_by(ID) %>% 
  ggplot(aes(x = as.numeric(week), y = value, color = ID)) +
  geom_line() +
  facet_grid(.~group) +
  labs(title = "Observations on each subject over 8 weeks", 
       x = "week",
       y = "value of observations"
       )
```

On week 1, the mean observation values for the control group was `r round(mean(filter(data, group == "con", week == 1)$value), digits = 3)` and that of the experimental group was `r round(mean(filter(data, group == "exp", week == 1)$value), digits = 3)`. Though both the control arm and the experimental arm started off around 1, values in the experimental arm showed a significant increase over the 8-week course and ended up around `r round(mean(filter(data, group == "exp", week == 8)$value), digits = 3)` on average, while the observation values of the control arm stayed relatively steady over time around `r round(mean(filter(data, group == "con", week == 8)$value), digits = 3)`. 








### Problem 2


```{r}
# load homicide data
homicide_data <- 
  read_csv("./data/homicide-data.csv") %>% 
  janitor::clean_names()
```

`homicide-data.csv` records `r dim(homicide_data)[1]` cases of homicide across `r dim(distinct(homicide_data, city))[1]` in `r dim(distinct(homicide_data, state))[1]` different states. The observations are `UID`, `reported_date`, victim's name, race, age and sex; geographic locations of the case, disposition of each case("Closed by arrest", "Closed without arrest" or "Open/No arrest").



```{r}
#Create `city_state` variable
homicide_data <- 
  homicide_data %>% 
  mutate(city_state = str_c(city, ",", state)) %>% 
  select(-city, -state) # tidy the table
```

```{r}
# summarize within cities to obtain the total number of homicides
homicide_data <- 
  homicide_data %>% 
  group_by(city_state) %>% 
  mutate(total = length(uid))

# the number of unsolved = total - solved
homicide_data <- 
  homicide_data %>% 
  filter(disposition == "Closed by arrest") %>% 
  group_by(city_state) %>% 
  mutate(unsolved = total - length(uid))

# Table that shows total and unsolved cases
unsolved_data <- 
  homicide_data %>% 
  distinct(city_state, unsolved, total)
unsolved_data %>% 
  knitr::kable()
```



```{r}
# prop.test Baltimore
prop_Ba <-  
  prop.test(x = unsolved_data$unsolved[unsolved_data$city_state == "Baltimore,MD"], 
            n = unsolved_data$total[unsolved_data$city_state == "Baltimore,MD"],
            alternative = "two.sided") %>% 
  broom::tidy() 

# pull the estimated proportion and confidence intervals 
prop_Ba["estimate"]
cbind(prop_Ba["conf.low"], prop_Ba["conf.high"])
```

